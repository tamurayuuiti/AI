<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>顔検出カメラ</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        /* 動画とキャンバスの重なりを調整 */
        body, html { margin: 0; overflow: hidden; }
        video, canvas { position: absolute; top: 0; left: 0; }
    </style>
</head>
<body>
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>

    <script>
        // モデルの読み込み
        async function loadModels() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        }

        // カメラの設定と開始
        async function startCamera() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                video.play();
                detectFaces();
            };
        }

        // 顔検出と枠線描画
        async function detectFaces() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('overlay');
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            // 顔検出を100msごとに繰り返し
            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
            }, 100);
        }

        // 初期化
        (async function init() {
            await loadModels();
            await startCamera();
        })();
    </script>
</body>
</html>
