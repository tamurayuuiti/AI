<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>画像からの顔検出テスト</title>
    <!-- face-api.jsの読み込み -->
    <script defer src="libs/tf.min.js"></script>
    <script defer src="libs/face-api.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; display: flex; flex-direction: column; align-items: center; background-color: #f0f0f0; margin: 0; padding: 20px; }
        #container { text-align: center; background-color: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
        h1 { color: #333; }
        input[type="file"] { margin-top: 10px; }
        canvas { margin-top: 20px; border: 2px solid #333; border-radius: 8px; }
        #status { font-size: 18px; color: #007bff; margin-top: 10px; }
    </style>
</head>
<body>
    <div id="container">
        <h1>画像からの顔検出テスト</h1>
        <p>顔が含まれる画像をアップロードしてください。</p>
        <input type="file" id="imageUpload" accept="image/*">
        <div id="status">モデル読み込み中...</div>
        <canvas id="overlay"></canvas>
    </div>
    <script>
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');
        const statusElement = document.getElementById('status');
        const imageUpload = document.getElementById('imageUpload');
        
        async function loadModels() {
            // モデルの読み込み。指定URLは変更禁止
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://tamurayuuiti.github.io/AI/models/tiny_face_detector_model-weights_manifest.json');
            await faceapi.nets.faceLandmark68Net.loadFromUri('https://tamurayuuiti.github.io/AI/models/face_landmark_68_model-weights_manifest.json');
            await faceapi.nets.faceRecognitionNet.loadFromUri('https://tamurayuuiti.github.io/AI/models/face_recognition_model-weights_manifest.json');
            statusElement.textContent = "モデルの読み込みが完了しました。画像をアップロードしてください。";
        }

        async function detectFaces(image) {
            statusElement.textContent = "顔検出中...";
            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });
            const detections = await faceapi.detectAllFaces(image, options).withFaceLandmarks().withFaceDescriptors();

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (detections.length > 0) {
                console.log("顔検出成功:", detections.length, "個の顔が検出されました。");
                detections.forEach((detection, index) => {
                    const { x, y, width, height } = detection.detection.box;

                    ctx.strokeStyle = "lime";
                    ctx.lineWidth = 3;
                    ctx.strokeRect(x, y, width, height);
                    ctx.fillStyle = "white";
                    ctx.font = "18px Arial";
                    ctx.fillText(`顔${index + 1}`, x, y - 10);
                });
                statusElement.textContent = `${detections.length}個の顔が検出されました。`;
            } else {
                console.log("顔が検出されませんでした。");
                statusElement.textContent = "顔が検出されませんでした。";
            }
        }

        imageUpload.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;

            const image = new Image();
            image.onload = async () => {
                canvas.width = image.width;
                canvas.height = image.height;
                ctx.drawImage(image, 0, 0);
                await detectFaces(image);
            };
            image.src = URL.createObjectURL(file);
        });

        loadModels();
    </script>
</body>
</html>
